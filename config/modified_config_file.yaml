# #  SALVATORE MAIN MODIFICATIONS: 
# - model setted to AFNO, removing the embeded small block, high_res_low_res_ratio, and the out shape
# - set in_channel to 1 because I have only ws
# - specify the datasets for train_input, train_target, val_input, val_target, loss, specify output and input variable.

# IGNORE FOLLOWING COMMENTS:

# SPDX-FileCopyrightText: Copyright (c) 2023 - 2024 NVIDIA CORPORATION & AFFILIATES.
# SPDX-FileCopyrightText: All rights reserved.
# SPDX-License-Identifier: Apache-2.0
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# section defines the architecture of the neural network
model:
  model_type: "Spatial AFNO"
  model_name: "ws_spatial_afno"
  inp_shape: [250,250] #[105, 175]    # # Salvatore: inp_shape taken from the dimensions y and x from scripts of climatolab
  #out_shape: [250,250]                # # Salvatore:  out_shape not important, = to inp_shape
  in_channels: 1                       # # Salvatore: the model takes 1 variables and not 6 anymore
  out_channels: 1                      # and predicts 1 single variable
  
# # Salvatore: in the AFNO the class embded_model is not required 

 #embed_model:                         # separate small network thats is a 4 
 #  dim: 64                            # layer convolutional networks that 
 #  depth: 4                           # take 6 input channels and convert them
 #  activation_fn: "gelu"              # into a 64 dimensional feature space
 #  method: "static_conv"
  patch_size: [25, 25] # il modello processa l immagine in input in patches 5x5
  embed_dim: 512 # the main afno model works in a 512 dim feature space
  depth: 8       # number of ModAFNO layers stacked
  num_blocks: 4  # number of Fourier blocks in each ModAFNO layer
  drop_rate: 0   # no neuron dropout
# # Salvatore: in the AFNO the class modulate_mlp and modulate_filter are not required 
 # modulate_mlp: False    (True to modulate the mlp, i.e. to use ModAFNO; False to use just AFNO, without modulation)
 # modulate_filter: False (True to modulate the filter, i.e. to use ModAFNO; False to use just AFNO, without modulation)


# defining all the data used for training and validation:
# # Salvatore: I added the valuation and train masks path, 
sources:
  dataset:
    train_input: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/train_data_m_s_2010_2019_pen_CERRA.nc"
    train_target: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2010-2019/AEMET/aemet_daily-wind_m_s_2010-2019_CERRA.nc"
    train_mask: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2010-2019/AEMET/mask_aemet_daily-wind_m_s_2010-2019_CERRA.nc"
    val_input: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/val_data_m_s_2020_2020_pen_CERRA.nc"
    val_target: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2020-2020/AEMET/aemet_daily-wind_m_s_2020-2020_CERRA.nc"
    val_mask: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2020-2020/AEMET/mask_aemet_daily-wind_m_s_2020-2020_CERRA.nc"
    name: CERRA # Copernicus regional reanalysis for Europe (CERRA)
    input_variables: [
      'ws'
    ]
    output_variables: [
      'ws'
    ]
    mask_variables: [
      'ws'
    ]
    # # Salvatore: highr_res_low_res_ratio not require
    # high_res_low_res_ratio: 4
    # normalization substracting the mean and dividing by the standard deviation
    normalization:
      method: 'z_score' # Options: z_score, z_score_per_pixel, minmax, minmax_per_pixel, none
      input_stats_path: "data/stats/input_train_stats.npz"
      compute_target_stats: True # If True, normalize also the target variable
      target_stats_path: "data/stats/target_train_stats.npz"
      
# # Salvatore: the following classes are unchanged, just retouch some names in mlflow for having a not complete different thing   
# training on a small loop for a quick test
training:
  max_epoch: 4
  checkpoint_dir: "./checkpoints/"
  checkpoint_every: 1
  patience: 40
  save_best_checkpoint: True

# section for definie how to test the model and how to use it to make predictions
evaluation: 
  checkpoint_dir: "./checkpoints/"
  inference_on_epoch: "best" # Options: "best" or a specific epoch number
 
inference:
  inference_results: "./inference_results/"
  inference_maps_dir: "./inference_results/maps/"
  inference_input: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/test_mask_m_s_2021_2022_pen_CERRA.nc"
  inference_mask: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2021-2022/AEMET/mask_aemet_daily-wind_m_s_2021-2022_CERRA.nc"
  inference_target: "5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2021-2022/AEMET/aemet_daily-wind_m_s_2021-2022_CERRA.nc"

# more detailed hyperparameters for training process (batch size, optimizer, loss)
training_args:
  batch_size: 8
  num_workers: 4
  loss:
    loss_type: "holeloss" # Options: "mse", "rmse", "logrmse", "logmse", 
    # "maskedmenasquareloss", "holeloss", "charbonnier", "combined"
    eps: 1e-8
    log_weight: 0.5
  optimizer:
    optimizer_type: "AdamW"
    optimizer_params:
      lr: 4e-5
      weight_decay: 1e-4 

# mlflow logging settings
logging:
  mlflow:
    use_mlflow: True
    experiment_name: " ws predictions AFNO - No Modulation - 2010-2022 Dataset"
    experiment_desc: "High-resolution air pollution downscaling using Spatial ModAFNO"
    run_name: "Patch_size [5, 5]:  embed_dim: 512, depth:8, num_blocks:4, dropout:0, run-${now:%Y-%m-%d_%H-%M-%S}"
    run_desc: >
      Data from 2010 - 2020 splited randmly in train, val, test.
      Normalization: z_score
      Testing:
      patch_size: [5, 5] -
      embed_dim: 512 
      depth: 8      
      num_blocks: 4 
      drop_rate: 0 -
      loss: mse -
      optimizer: AdamW -
      lr: 4e-5 -
      wd: 1e-4 -      
    user_name: "Salvatore Conza Angelo"

metrics:
  metrics_dir: "./metrics/"
  metrics_file: "./metrics/metrics_val_no_modulation_whole_dataset_final_3.txt"
  pred_path: "./inference_results/maps/"
  pred_dataset: "ws_2025_11_28_09:11:38.nc"
  gt_path: "./5.-Data_Split_train_val_test/CERRA/Split_data_2010-2022/ByYear/2021-2022/AEMET/" 
  gt_dataset: "aemet_daily-wind_m_s_2021-2022_CERRA.nc"
  variables: [
      'ws'
    ]